{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem - solution approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Architecture and the Resilient Distributed Dataset\n",
    "The main components of the Spark architecture are the driver (accessed throw SparkContect object in pyspark) and executors. For each PySpark application, there will be one driver program and one or more executors running on the cluster slave machine. You might be wondering, what is an application in the context of PySpark? An application is a whole bunch of code used to solve a problem.\n",
    "\n",
    "The driver is the process that coordinates with many executors running on various slave machines. Spark follows a master/slave architecture. The SparkContext object is created by the driver. SparkContext is the main entry point to a PySpark application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can perform two types of operations on the RDD:** transformation and action              . Transformation on an RDD returns another RDD. We know that RDDs are immutable; therefore, changing the RDD is impossible. Hence transformations always return another RDD. Transformations are lazy, whereas actions are eagerly evaluated. I say that the transformation is lazy because whenever a transformation is applied to an RDD, that operation is not applied to the data at the same time. Instead, PySpark notes the operation request, but all the transformations are applied when the first action is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1: Create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a python list of float\n",
    "plist = [1.2 , 2.3 , 3.4 , 4.5 , 2.4 , 2.3, 4.0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2, 2.3, 3.4, 4.5, 2.4, 2.3, 4.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the pyspark\n",
    "import findspark\n",
    "findspark.init('/opt/spark/spark-3.0.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000018F492E7610>\n",
      "<SparkContext master=local[*] appName=RDD>\n"
     ]
    }
   ],
   "source": [
    "#create the session and sparkcontext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print(spark)\n",
    "print(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "parPythonData = sc.parallelize(plist,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a lazy definition\n",
    "parPythonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2, 2.3, 3.4, 4.5, 2.4, 2.3, 4.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we avaluate\n",
    "parPythonData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parPythonData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2, 2.3, 3.4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parPythonData.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of // partitions\n",
    "parPythonData.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem2 : You are given daily temperatures in Fahrenheit. You want to perform some analysis on that data. But your new software takes input in Celsius!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$^oC = (^oF – 32) × 5/9$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempData = [59,57.2,53.6,55.4,51.8,53.6,55.4]\n",
    "parTempData = sc.parallelize(tempData,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftoc = lambda tempf: (tempf -32) *5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.666666666666668"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftoc(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parCentigradeData = parTempData.map(ftoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0, 14.000000000000002, 12.0, 13.0, 10.999999999999998, 12.0, 13.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parCentigradeData.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering temp greater than $13^o$ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmorethan13 = lambda t: t >=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more general\n",
    "tmorethan = lambda threshold: lambda t: t >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>.<locals>.<lambda>(t)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmorethan(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredTemprature = parCentigradeData.filter(tmorethan13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0, 14.000000000000002, 13.0, 13.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredTemprature.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0, 14.000000000000002]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parCentigradeData.filter(tmorethan(14)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 3: Data manipulation and run aggregation operations (avg, sums, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given data indicating student grades for a two-sessions exams. eight students are enrolled in this course.\n",
    "Calculate the following:\n",
    "* Average grades per session, each semester, for each student\n",
    "* Top three students who have the highest average grades in the second year\n",
    "* Bottom three students who have the lowest average grades in the second year\n",
    "* All students who have earned more than an 80% average in the second semester of the second semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawstudentsfile = sc.textFile('students.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawstudentsfile.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Student\\tSemester\\tGrade1\\tGarde2', 'st1\\ts1\\t65\\t75', 'st1\\ts2\\t74\\t90']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawstudentsfile.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanstudentsfiles = rawstudentsfile.filter(lambda line: line.startswith('st'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st1\\ts1\\t65\\t75',\n",
       " 'st1\\ts2\\t74\\t90',\n",
       " 'st2\\ts1\\t75\\t85',\n",
       " 'st2\\ts2\\t70\\t80',\n",
       " 'st3\\ts1\\t78\\t75',\n",
       " 'st3\\ts2\\t81\\t85',\n",
       " 'st4\\ts1\\t20\\t50',\n",
       " 'st4\\ts2\\t60\\t65',\n",
       " 'st5\\ts1\\t65\\t75',\n",
       " 'st5\\ts2\\t74\\t90',\n",
       " 'st6\\ts1\\t75\\t85',\n",
       " 'st6\\ts2\\t77\\t88',\n",
       " 'st7\\ts1\\t76\\t91',\n",
       " 'st7\\ts2\\t65\\t45',\n",
       " 'st8\\ts1\\t70\\t70',\n",
       " 'st8\\ts2\\t80\\t75']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanstudentsfiles.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentMarksData = cleanstudentsfiles.map(lambda line: line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentMarksData.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st1', 's1', '65', '75'],\n",
       " ['st1', 's2', '74', '90'],\n",
       " ['st2', 's1', '75', '85'],\n",
       " ['st2', 's2', '70', '80'],\n",
       " ['st3', 's1', '78', '75'],\n",
       " ['st3', 's2', '81', '85'],\n",
       " ['st4', 's1', '20', '50'],\n",
       " ['st4', 's2', '60', '65'],\n",
       " ['st5', 's1', '65', '75'],\n",
       " ['st5', 's2', '74', '90'],\n",
       " ['st6', 's1', '75', '85'],\n",
       " ['st6', 's2', '77', '88'],\n",
       " ['st7', 's1', '76', '91'],\n",
       " ['st7', 's2', '65', '45'],\n",
       " ['st8', 's1', '70', '70'],\n",
       " ['st8', 's2', '80', '75']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentMarksData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentMarksDataRDD = studentMarksData.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentMarksDataRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st4', 's2', '60', '65'],\n",
       " ['st5', 's1', '65', '75'],\n",
       " ['st5', 's2', '74', '90'],\n",
       " ['st6', 's1', '75', '85'],\n",
       " ['st6', 's2', '77', '88'],\n",
       " ['st7', 's1', '76', '91'],\n",
       " ['st7', 's2', '65', '45'],\n",
       " ['st8', 's1', '70', '70'],\n",
       " ['st8', 's2', '80', '75'],\n",
       " ['st1', 's1', '65', '75'],\n",
       " ['st1', 's2', '74', '90'],\n",
       " ['st2', 's1', '75', '85'],\n",
       " ['st2', 's2', '70', '80'],\n",
       " ['st3', 's1', '78', '75'],\n",
       " ['st3', 's2', '81', '85'],\n",
       " ['st4', 's1', '20', '50']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentMarksDataRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Average Session Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentMarksMean = studentMarksDataRDD.map(lambda x : [x[0],x[1],(int(x[2])+int(x[3]))/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$[x_0,x_1,x_2,x_3] \\mapsto [x_0,x_1,(x_2+x_3)/2]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st4', 's2', 62.5],\n",
       " ['st5', 's1', 70.0],\n",
       " ['st5', 's2', 82.0],\n",
       " ['st6', 's1', 80.0],\n",
       " ['st6', 's2', 82.5],\n",
       " ['st7', 's1', 83.5],\n",
       " ['st7', 's2', 55.0],\n",
       " ['st8', 's1', 70.0],\n",
       " ['st8', 's2', 77.5],\n",
       " ['st1', 's1', 70.0],\n",
       " ['st1', 's2', 82.0],\n",
       " ['st2', 's1', 80.0],\n",
       " ['st2', 's2', 75.0],\n",
       " ['st3', 's1', 76.5],\n",
       " ['st3', 's2', 83.0],\n",
       " ['st4', 's1', 35.0]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentMarksMean.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondSemMarks = studentMarksMean.filter(lambda x : \"s2\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st4', 's2', 62.5],\n",
       " ['st5', 's2', 82.0],\n",
       " ['st6', 's2', 82.5],\n",
       " ['st7', 's2', 55.0],\n",
       " ['st8', 's2', 77.5],\n",
       " ['st1', 's2', 82.0],\n",
       " ['st2', 's2', 75.0],\n",
       " ['st3', 's2', 83.0]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondSemMarks.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedMarksData = secondSemMarks.sortBy(keyfunc = lambda x : -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st3', 's2', 83.0],\n",
       " ['st6', 's2', 82.5],\n",
       " ['st5', 's2', 82.0],\n",
       " ['st1', 's2', 82.0],\n",
       " ['st8', 's2', 77.5],\n",
       " ['st2', 's2', 75.0],\n",
       " ['st4', 's2', 62.5],\n",
       " ['st7', 's2', 55.0]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedMarksData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st7', 's2', 55.0],\n",
       " ['st4', 's2', 62.5],\n",
       " ['st2', 's2', 75.0],\n",
       " ['st8', 's2', 77.5],\n",
       " ['st5', 's2', 82.0],\n",
       " ['st1', 's2', 82.0],\n",
       " ['st6', 's2', 82.5],\n",
       " ['st3', 's2', 83.0]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondSemMarks.sortBy(keyfunc = lambda x : x[2]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st3', 's2', 83.0], ['st6', 's2', 82.5], ['st5', 's2', 82.0]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top 3\n",
    "sortedMarksData.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our answer. But can we optimize it further? In order to get top-three data, we are sorting the whole list. We can optimize this by using the takeOrdered() function. This function takes two arguments: the number of elements we require, and key, which uses a lambda function to determine how to take the data out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "topThreeStudents = secondSemMarks.takeOrdered(num=3, key = lambda x :-x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['st3', 's2', 83.0], ['st6', 's2', 82.5], ['st5', 's2', 82.0]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topThreeStudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print the result, we are not using the collect() function to get the data. Remember that transformation creates another RDD, so we require the collect() function to collect data. But an action will directly fetch the data to the driver, and collect() is not required. So you can conclude that the takeOrdered() function is an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
